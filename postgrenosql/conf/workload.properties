# bin/ycsb load postgrenosql -P workloads/workloadf -P postgrenosql/conf/workload.properties -P postgrenosql/conf/postgrenosql.properties
# The table that need to be created is:

# CREATE TABLE public.current_aggregate_versions (
#     id bigint NOT NULL,
#     aggregate_id character varying NOT NULL,
#     current_version bigint NOT NULL,
#     type character varying,
#     data bytea,
#     organization_id character varying,
#     compressed boolean,
#     synchronization_id character varying,
#     epoch bigint,
#     dirty_synchronization boolean DEFAULT false,
#     primary key(id)
# );


# --
# -- Name: current_aggregate_versions_id_seq; Type: SEQUENCE; Schema: public; Owner: -
# --

# CREATE SEQUENCE public.current_aggregate_versions_id_seq
#     START WITH 1
#     INCREMENT BY 1
#     NO MINVALUE
#     NO MAXVALUE
#     CACHE 1;


# --
# -- Name: current_aggregate_versions_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: -
# --

# ALTER SEQUENCE public.current_aggregate_versions_id_seq OWNED BY public.current_aggregate_versions.id;

# --
# -- Name: current_aggregate_versions id; Type: DEFAULT; Schema: public; Owner: -
# --

# ALTER TABLE ONLY public.current_aggregate_versions ALTER COLUMN id SET DEFAULT nextval('public.current_aggregate_versions_id_seq'::regclass);

# --
# -- Name: current_aggregate_versions current_aggregate_versions_pkey; Type: CONSTRAINT; Schema: public; Owner: -
# --

# -- ALTER TABLE ONLY public.current_aggregate_versions
# --     ADD CONSTRAINT current_aggregate_versions_pkey PRIMARY KEY (id);

# --
# -- Name: index_current_aggregate_versions_on_aggregate_id; Type: INDEX; Schema: public; Owner: -
# --

# CREATE UNIQUE INDEX index_current_aggregate_versions_on_aggregate_id ON public.current_aggregate_versions USING lsm (aggregate_id HASH);


# Number of thread -threads <v>
# Target operations/s -target <v>

# Why not name it something appropriate :)
table=current_aggregate_versions

# Number of recrods. Setting this to 30000000 gives us about 300GB of data
recordcount=1000
batchsize=10

# We don't care much about field count, it represents how many 'column' our documents have. In our case the CAV has a single data entry
fieldcount=7
# That data entry will be 10kB for each! 
fieldlength=10000

operationcount=20

# We mostly do have mrw but the indexing jobs also query
#readmodifywriteproportion=0.75
readproportion=0.0

# This is the default for workloadf, it should pick 'hot' aggregates and increase traffic pattern for those aggregates.
# I think this does somewhat mirror indexing in the some orgs are more active than others, and we don't have uniform
# access across all our aggregates, the alernative option here is 'uniform'
requestdistribution=special

# measurementtype=supported measurement types are hdrhistogram, histogram and timeseries (default: hdrhistogram)

readmodifywriteproportion=0
bulkreadmodifywriteproportion=1.0

measurementtype=timeseries
timeseries.granularity=2000